{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5096ff88",
   "metadata": {},
   "source": [
    "# LOGISTIC REGRESSION \n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2021/10/building-an-end-to-end-logistic-regression-model/\n",
    "\n",
    "### I hope the preceding discussion has provided us with a better understanding of machine learning and its various types. Logistic Regression is a Machine Learning method that is used to solve classification issues. It is a predictive analytic technique that is based on the probability idea. The classification algorithm Logistic Regression is used to predict the likelihood of a categorical dependent variable. The dependant variable in logistic regression is a binary variable with data coded as 1 (yes, True, normal, success, etc.) or 0 (no, False, abnormal, failure, etc.).\n",
    "\n",
    "The goal of Logistic Regression is to discover a link between characteristics and the likelihood of a specific outcome. For example, when predicting whether a student passes or fails an exam based on the number of hours spent studying, the response variable has two values: pass and fail.\n",
    "\n",
    "A Logistic Regression model is similar to a Linear Regression model, except that the Logistic Regression utilizes a more sophisticated cost function, which is known as the “Sigmoid function” or “logistic function” instead of a linear function.\n",
    "\n",
    "Many people may have a question, whether Logistic Regression is a classification or regression category. The logistic regression hypothesis suggests that the cost function be limited to a value between 0 and 1. As a result, linear functions fail to describe it since it might have a value larger than 1 or less than 0, which is impossible according to the logistic regression hypothesis.\n",
    "\n",
    "Behind every great leader, there was an even greater logistician.\n",
    "\n",
    "This article was published as a part of the Data Science Blogathon\n",
    "\n",
    " \n",
    "\n",
    "Hey guys! Good day to all, today we are going to see an interesting algorithm in the Machine Learning technique, called Logistic Regression. So before getting into the topic, we shall brush up on some basic terminologies, to understand it clearly.\n",
    "\n",
    "What is Machine Learning?\n",
    "Machine Learning algorithms can access data (categorical, numerical, image, video, or anything) and use it to learn for themselves without any explicit programming. But how does the Machine Learning technique work? just by observing the data (through instructions to observe the pattern and making decisions or predictions)\n",
    "\n",
    "Types of Machine Learning:\n",
    "Machine Learning algorithmic techniques can be broadly classified into three types,\n",
    "\n",
    "Supervised Machine Learning – Task Driven (Classification and Regression)\n",
    "Unsupervised Machine Learning – Data-Driven (Clustering)\n",
    "Reinforcement Machine Learning – Learning from mistakes (Rewards or Punishment)\n",
    "Supervised Machine Learning:\n",
    "Algorithms are trained in supervised learning utilizing labeled datasets, where the algorithm learns about each category of input. When the training phase is finished, the algorithm is evaluated on test data (a subset of the training set) and predicts the result. Supervised Machine Learning is classified into two types,\n",
    "\n",
    "Loading Image\n",
    "Become a Full-Stack Data Scientist\n",
    "Power Ahead in your AI ML Career | No Pre-requisites Required\n",
    "Download Brochure\n",
    "Regression\n",
    "\n",
    "If there is a link between the input variable and the output variable, regression procedures are applied. It is used to forecast continuous variables such as weather, market trends, and so on.\n",
    "\n",
    "Classification\n",
    "\n",
    "When the output variable is categorical, such as Yes-No, Male-Female, True-False, Normal – Abnormal, and so on, classification methods are used.\n",
    "\n",
    "What is Logistic Regression?\n",
    "I hope the preceding discussion has provided us with a better understanding of machine learning and its various types. Logistic Regression is a Machine Learning method that is used to solve classification issues. It is a predictive analytic technique that is based on the probability idea. The classification algorithm Logistic Regression is used to predict the likelihood of a categorical dependent variable. The dependant variable in logistic regression is a binary variable with data coded as 1 (yes, True, normal, success, etc.) or 0 (no, False, abnormal, failure, etc.).\n",
    "\n",
    "The goal of Logistic Regression is to discover a link between characteristics and the likelihood of a specific outcome. For example, when predicting whether a student passes or fails an exam based on the number of hours spent studying, the response variable has two values: pass and fail.\n",
    "\n",
    "A Logistic Regression model is similar to a Linear Regression model, except that the Logistic Regression utilizes a more sophisticated cost function, which is known as the “Sigmoid function” or “logistic function” instead of a linear function.\n",
    "\n",
    "Many people may have a question, whether Logistic Regression is a classification or regression category. The logistic regression hypothesis suggests that the cost function be limited to a value between 0 and 1. As a result, linear functions fail to describe it since it might have a value larger than 1 or less than 0, which is impossible according to the logistic regression hypothesis.\n",
    "\n",
    "Behind every great leader, there was an even greater logistician.\n",
    "\n",
    " \n",
    "\n",
    "Logistic Regression Model Image\n",
    "To answer this question, Logistic Regression is considered a regression model also. This model creates a regression model to predict the likelihood that a given data entry belongs to the category labeled “1.” Logistic regression models the data using the sigmoid function, much as linear regression assumes that the data follows a linear distribution.\n",
    "\n",
    "Why the name Logistic Regression?\n",
    "It’s called ‘Logistic Regression’ since the technique behind it is quite similar to Linear Regression. The name “Logistic” comes from the Logit function, which is utilized in this categorization approach.\n",
    "\n",
    "Why we can’t use Linear Regression instead of Logistic Regression?\n",
    "Before answering this question, we will explain from Linear Regression concept, from the scratch then only we can understand it better. Although logistic regression is a sibling of linear regression, it is a classification technique, despite its name. Mathematically linear regression can be explained by,\n",
    "\n",
    "y = mx + c\n",
    "\n",
    "y – predicted value\n",
    "\n",
    "m – slope of the line\n",
    "\n",
    "x – input data\n",
    "\n",
    "c- Y-intercept or slope\n",
    "\n",
    "We can forecast y values such as using these values. Now observe the below diagram for a better understanding,\n",
    "\n",
    "Linear Regression GIF\n",
    "The x values are represented by the blue dots (the input data). We can now compute slope and y coordinate using the input data to ensure that our projected line (red line) covers most of the locations. We can now forecast any value of y given its x values using this line.\n",
    "\n",
    "One thing to keep in mind about linear regression is that it only works with continuous data. If we want to include linear regression in our classification methods, we’ll have to adjust our algorithm a little more. First, we must choose a threshold so that if our projected value is less than the threshold, it belongs to class 1; otherwise, it belongs to class 2.\n",
    "\n",
    "Now, if you’re thinking, “Oh, that’s simple, just create linear regression with a threshold, and hurray!, classification method,” there’s a catch. We must specify the threshold value manually, and calculating the threshold for huge datasets will be impossible. Furthermore, even if our anticipated values vary, the threshold value will remain the same. A logistic regression, on the other hand, yields a logistic curve with values confined to 0 and 1. The curve in logistic regression is generated using the natural logarithm of the target variable’s “odds,” rather than the probability, as in linear regression. Furthermore, the predictors need not be regularly distributed or have the same variance in each group.\n",
    "\n",
    "And now the question?\n",
    "\n",
    "This famous title question was explained by our beloved person Andrew Ng, assume we have information about tumor size and malignancy. Because this is a classification issue, we can see that all the values will fall between 0 and 1. And, by fitting the best-found regression line and assuming a threshold of 0.5, we can do a very good job with the line.\n",
    "\n",
    "Plotting the Regression Line\n",
    "We can choose a point on the x-axis from which all values on the left side are regarded as negative, and all values on the right side are considered positive.\n",
    "\n",
    "Adding threshold value | Logistic Regression\n",
    "But what if the data contains an outlier? Things would become shambles. For 0.5 thresholds, for example,\n",
    "\n",
    "Plotting Outlier in the graph\n",
    "Even if we fit the best-found regression line, we won’t be able to determine any point where we can distinguish classes. It will insert some instances from the positive class into the negative class. The green dotted line (Decision Boundary) separates malignant and benign tumors, however, it should have been a yellow line that clearly separates the positive and negative cases. As a result, even a single outlier can throw the linear regression estimates off. And it’s here that logistic regression comes into play.\n",
    "\n",
    "Logit function to Sigmoid Function – Logistic Regression:\n",
    "Logistic Regression can be expressed as,\n",
    "\n",
    "\n",
    "\n",
    "where p(x)/(1-p(x)) is termed odds, and the left-hand side is called the logit or log-odds function. The odds are the ratio of the chances of success to the chances of failure. As a result, in Logistic Regression, a linear combination of inputs is translated to log(odds), with an output of 1.\n",
    "\n",
    "The following is the inverse of the aforementioned function\n",
    "\n",
    "\n",
    "\n",
    "This is the Sigmoid function, which produces an S-shaped curve. It always returns a probability value between 0 and 1. The Sigmoid function is used to convert expected values to probabilities. The function converts any real number into a number between 0 and 1. We utilize sigmoid to translate predictions to probabilities in machine learning.\n",
    "\n",
    "The mathematically sigmoid function can be,\n",
    "\n",
    "\n",
    "\n",
    "Sigmoid Function | Logistic Regression\n",
    "Types of Logistic Regression:\n",
    "In general, it can be classified into,\n",
    "\n",
    "1. Binary Logistic Regression – two or binary outcomes like yes or no\n",
    "\n",
    "2. Multinomial Logistic Regression – three or more outcomes like first, second, and third class or no class degree\n",
    "\n",
    "3. Ordinal Logistic Regression – three or more like multinomial logistic regression but here with the order like customer rating in the supermarket from 1 to 5\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Requirements for Logistic Regression to work well\n",
    "This model can work for all the datasets, but still, if you need good performance, then there will be some assumptions to consider,\n",
    "\n",
    "1. The dependant variable in binary logistic regression must be binary.\n",
    "\n",
    "2. Only the variables that are relevant should be included.\n",
    "\n",
    "3. The independent variables must be unrelated to one another. That is, there should be minimal or no multicollinearity in the model.\n",
    "\n",
    "4. The log chances are proportional to the independent variables.\n",
    "\n",
    "5. Large sample sizes are required for logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9a44750",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792a3a42",
   "metadata": {},
   "source": [
    "## Import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a53125b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Social_Network_Ads.csv')\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4325b854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>19000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>43000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>57000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>76000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>46</td>\n",
       "      <td>41000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>51</td>\n",
       "      <td>23000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>50</td>\n",
       "      <td>20000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>36</td>\n",
       "      <td>33000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>49</td>\n",
       "      <td>36000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age  EstimatedSalary  Purchased\n",
       "0     19            19000          0\n",
       "1     35            20000          0\n",
       "2     26            43000          0\n",
       "3     27            57000          0\n",
       "4     19            76000          0\n",
       "..   ...              ...        ...\n",
       "395   46            41000          1\n",
       "396   51            23000          1\n",
       "397   50            20000          1\n",
       "398   36            33000          0\n",
       "399   49            36000          1\n",
       "\n",
       "[400 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6a91f2",
   "metadata": {},
   "source": [
    "## Splitting dataset into the Training set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cb56ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82ecc899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    44  39000]\n",
      " [    32 120000]\n",
      " [    38  50000]\n",
      " [    32 135000]\n",
      " [    52  21000]\n",
      " [    53 104000]\n",
      " [    39  42000]\n",
      " [    38  61000]\n",
      " [    36  50000]\n",
      " [    36  63000]\n",
      " [    35  25000]\n",
      " [    35  50000]\n",
      " [    42  73000]\n",
      " [    47  49000]\n",
      " [    59  29000]\n",
      " [    49  65000]\n",
      " [    45 131000]\n",
      " [    31  89000]\n",
      " [    46  82000]\n",
      " [    47  51000]\n",
      " [    26  15000]\n",
      " [    60 102000]\n",
      " [    38 112000]\n",
      " [    40 107000]\n",
      " [    42  53000]\n",
      " [    35  59000]\n",
      " [    48  41000]\n",
      " [    48 134000]\n",
      " [    38 113000]\n",
      " [    29 148000]\n",
      " [    26  15000]\n",
      " [    60  42000]\n",
      " [    24  19000]\n",
      " [    42 149000]\n",
      " [    46  96000]\n",
      " [    28  59000]\n",
      " [    39  96000]\n",
      " [    28  89000]\n",
      " [    41  72000]\n",
      " [    45  26000]\n",
      " [    33  69000]\n",
      " [    20  82000]\n",
      " [    31  74000]\n",
      " [    42  80000]\n",
      " [    35  72000]\n",
      " [    33 149000]\n",
      " [    40  71000]\n",
      " [    51 146000]\n",
      " [    46  79000]\n",
      " [    35  75000]\n",
      " [    38  51000]\n",
      " [    36  75000]\n",
      " [    37  78000]\n",
      " [    38  61000]\n",
      " [    60 108000]\n",
      " [    20  82000]\n",
      " [    57  74000]\n",
      " [    42  65000]\n",
      " [    26  80000]\n",
      " [    46 117000]\n",
      " [    35  61000]\n",
      " [    21  68000]\n",
      " [    28  44000]\n",
      " [    41  87000]\n",
      " [    37  33000]\n",
      " [    27  90000]\n",
      " [    39  42000]\n",
      " [    28 123000]\n",
      " [    31 118000]\n",
      " [    25  87000]\n",
      " [    35  71000]\n",
      " [    37  70000]\n",
      " [    35  39000]\n",
      " [    47  23000]\n",
      " [    35 147000]\n",
      " [    48 138000]\n",
      " [    26  86000]\n",
      " [    25  79000]\n",
      " [    52 138000]\n",
      " [    51  23000]\n",
      " [    35  60000]\n",
      " [    33 113000]\n",
      " [    30 107000]\n",
      " [    48  33000]\n",
      " [    41  80000]\n",
      " [    48  96000]\n",
      " [    31  18000]\n",
      " [    31  71000]\n",
      " [    43 129000]\n",
      " [    59  76000]\n",
      " [    18  44000]\n",
      " [    36 118000]\n",
      " [    42  90000]\n",
      " [    47  30000]\n",
      " [    26  43000]\n",
      " [    40  78000]\n",
      " [    46  59000]\n",
      " [    59  42000]\n",
      " [    46  74000]\n",
      " [    35  91000]\n",
      " [    28  59000]\n",
      " [    40  57000]\n",
      " [    59 143000]\n",
      " [    57  26000]\n",
      " [    52  38000]\n",
      " [    47 113000]\n",
      " [    53 143000]\n",
      " [    35  27000]\n",
      " [    58 101000]\n",
      " [    45  45000]\n",
      " [    23  82000]\n",
      " [    46  23000]\n",
      " [    42  65000]\n",
      " [    28  84000]\n",
      " [    38  59000]\n",
      " [    26  84000]\n",
      " [    29  28000]\n",
      " [    37  71000]\n",
      " [    22  55000]\n",
      " [    48  35000]\n",
      " [    49  28000]\n",
      " [    38  65000]\n",
      " [    27  17000]\n",
      " [    46  28000]\n",
      " [    48 141000]\n",
      " [    26  17000]\n",
      " [    35  97000]\n",
      " [    39  59000]\n",
      " [    24  27000]\n",
      " [    32  18000]\n",
      " [    46  88000]\n",
      " [    35  58000]\n",
      " [    56  60000]\n",
      " [    47  34000]\n",
      " [    40  72000]\n",
      " [    32 100000]\n",
      " [    19  21000]\n",
      " [    25  90000]\n",
      " [    35  88000]\n",
      " [    28  32000]\n",
      " [    50  20000]\n",
      " [    40  59000]\n",
      " [    50  44000]\n",
      " [    35  72000]\n",
      " [    40 142000]\n",
      " [    46  32000]\n",
      " [    39  71000]\n",
      " [    20  74000]\n",
      " [    29  75000]\n",
      " [    31  76000]\n",
      " [    47  25000]\n",
      " [    40  61000]\n",
      " [    34 112000]\n",
      " [    38  80000]\n",
      " [    42  75000]\n",
      " [    47  47000]\n",
      " [    39  75000]\n",
      " [    19  25000]\n",
      " [    37  80000]\n",
      " [    36  60000]\n",
      " [    41  52000]\n",
      " [    36 125000]\n",
      " [    48  29000]\n",
      " [    36 126000]\n",
      " [    51 134000]\n",
      " [    27  57000]\n",
      " [    38  71000]\n",
      " [    39  61000]\n",
      " [    22  27000]\n",
      " [    33  60000]\n",
      " [    48  74000]\n",
      " [    58  23000]\n",
      " [    53  72000]\n",
      " [    32 117000]\n",
      " [    54  70000]\n",
      " [    30  80000]\n",
      " [    58  95000]\n",
      " [    26  52000]\n",
      " [    45  79000]\n",
      " [    24  55000]\n",
      " [    40  75000]\n",
      " [    33  28000]\n",
      " [    44 139000]\n",
      " [    22  18000]\n",
      " [    33  51000]\n",
      " [    43 133000]\n",
      " [    24  32000]\n",
      " [    46  22000]\n",
      " [    35  55000]\n",
      " [    54 104000]\n",
      " [    48 119000]\n",
      " [    35  53000]\n",
      " [    37 144000]\n",
      " [    23  66000]\n",
      " [    37 137000]\n",
      " [    31  58000]\n",
      " [    33  41000]\n",
      " [    45  22000]\n",
      " [    30  15000]\n",
      " [    19  19000]\n",
      " [    49  74000]\n",
      " [    39 122000]\n",
      " [    35  73000]\n",
      " [    39  71000]\n",
      " [    24  23000]\n",
      " [    41  72000]\n",
      " [    29  83000]\n",
      " [    54  26000]\n",
      " [    35  44000]\n",
      " [    37  75000]\n",
      " [    29  47000]\n",
      " [    31  68000]\n",
      " [    42  54000]\n",
      " [    30 135000]\n",
      " [    52 114000]\n",
      " [    50  36000]\n",
      " [    56 133000]\n",
      " [    29  61000]\n",
      " [    30  89000]\n",
      " [    26  16000]\n",
      " [    33  31000]\n",
      " [    41  72000]\n",
      " [    36  33000]\n",
      " [    55 125000]\n",
      " [    48 131000]\n",
      " [    41  71000]\n",
      " [    30  62000]\n",
      " [    37  72000]\n",
      " [    41  63000]\n",
      " [    58  47000]\n",
      " [    30 116000]\n",
      " [    20  49000]\n",
      " [    37  74000]\n",
      " [    41  59000]\n",
      " [    49  89000]\n",
      " [    28  79000]\n",
      " [    53  82000]\n",
      " [    40  57000]\n",
      " [    60  34000]\n",
      " [    35 108000]\n",
      " [    21  72000]\n",
      " [    38  71000]\n",
      " [    39 106000]\n",
      " [    37  57000]\n",
      " [    26  72000]\n",
      " [    35  23000]\n",
      " [    54 108000]\n",
      " [    30  17000]\n",
      " [    39 134000]\n",
      " [    29  43000]\n",
      " [    33  43000]\n",
      " [    35  38000]\n",
      " [    41  45000]\n",
      " [    41  72000]\n",
      " [    39 134000]\n",
      " [    27 137000]\n",
      " [    21  16000]\n",
      " [    26  32000]\n",
      " [    31  66000]\n",
      " [    39  73000]\n",
      " [    41  79000]\n",
      " [    47  50000]\n",
      " [    41  30000]\n",
      " [    37  93000]\n",
      " [    60  46000]\n",
      " [    25  22000]\n",
      " [    28  37000]\n",
      " [    38  55000]\n",
      " [    36  54000]\n",
      " [    20  36000]\n",
      " [    56 104000]\n",
      " [    40  57000]\n",
      " [    42 108000]\n",
      " [    20  23000]\n",
      " [    40  65000]\n",
      " [    47  20000]\n",
      " [    18  86000]\n",
      " [    35  79000]\n",
      " [    57  33000]\n",
      " [    34  72000]\n",
      " [    49  39000]\n",
      " [    27  31000]\n",
      " [    19  70000]\n",
      " [    39  79000]\n",
      " [    26  81000]\n",
      " [    25  80000]\n",
      " [    28  85000]\n",
      " [    55  39000]\n",
      " [    50  88000]\n",
      " [    49  88000]\n",
      " [    52 150000]\n",
      " [    35  65000]\n",
      " [    42  54000]\n",
      " [    34  43000]\n",
      " [    37  52000]\n",
      " [    48  30000]\n",
      " [    29  43000]\n",
      " [    36  52000]\n",
      " [    27  54000]\n",
      " [    26 118000]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178721eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
