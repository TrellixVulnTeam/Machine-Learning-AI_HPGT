{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24157d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sn \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0d5b42",
   "metadata": {},
   "source": [
    "# DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f078f200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset\n",
    "df = pd.read_csv('Data.csv')\n",
    "# assigning independent variables to X\n",
    "X = df.iloc[:, :-1].values\n",
    "# assigning dependent variables to y\n",
    "y = df.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "875f118d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['France' 44.0 72000.0]\n",
      " ['Spain' 27.0 48000.0]\n",
      " ['Germany' 30.0 54000.0]\n",
      " ['Spain' 38.0 61000.0]\n",
      " ['Germany' 40.0 nan]\n",
      " ['France' 35.0 58000.0]\n",
      " ['Spain' nan 52000.0]\n",
      " ['France' 48.0 79000.0]\n",
      " ['Germany' 50.0 83000.0]\n",
      " ['France' 37.0 67000.0]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f7ba0d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['No' 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes']\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb2aada1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking care of missing data\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputer.fit(X[:, 1:3])\n",
    "X[:, 1:3] = imputer.transform(X[:, 1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "896e78db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['France' 44.0 72000.0]\n",
      " ['Spain' 27.0 48000.0]\n",
      " ['Germany' 30.0 54000.0]\n",
      " ['Spain' 38.0 61000.0]\n",
      " ['Germany' 40.0 63777.77777777778]\n",
      " ['France' 35.0 58000.0]\n",
      " ['Spain' 38.77777777777778 52000.0]\n",
      " ['France' 48.0 79000.0]\n",
      " ['Germany' 50.0 83000.0]\n",
      " ['France' 37.0 67000.0]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b82152d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical data is when there are some data in a dataset which are not\n",
    "# many so one can easily change them into some numbers for a machine learning \n",
    "# to work on it perfectly\n",
    "# example in the above there are three countries in the independent variable\n",
    "# They are Germany, France and Spain: 0, 1, 3\n",
    "# that is the only way of dealing with categorical values\n",
    "# we could use oneHotEncoder or labelcoder\n",
    "# onehotencoder usual create new columns out of the dataset given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27809975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding independent\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c948e35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0 0.0 0.0 44.0 72000.0]\n",
      " [0.0 0.0 1.0 27.0 48000.0]\n",
      " [0.0 1.0 0.0 30.0 54000.0]\n",
      " [0.0 0.0 1.0 38.0 61000.0]\n",
      " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
      " [1.0 0.0 0.0 35.0 58000.0]\n",
      " [0.0 0.0 1.0 38.77777777777778 52000.0]\n",
      " [1.0 0.0 0.0 48.0 79000.0]\n",
      " [0.0 1.0 0.0 50.0 83000.0]\n",
      " [1.0 0.0 0.0 37.0 67000.0]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15da9f0e",
   "metadata": {},
   "source": [
    "# Encoding the Dependent Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f68f5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In dealing with dependent variable with deals with yes or no\n",
    "# use labelencoder since it comes with text\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8421d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 1 1 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f813933",
   "metadata": {},
   "source": [
    "# Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e342ad",
   "metadata": {},
   "source": [
    "Feature scaling is always applied after splitting the dataset\n",
    "because we want to prevent information leakage across the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a25afb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data in order to have a train and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a08d84",
   "metadata": {},
   "source": [
    "# Note the splitting carefully, the dataset is divided into two parts;\n",
    "\n",
    "## training and testing\n",
    "\n",
    "training dataset is divided into two x and y(that is x for independent variables and its corresponding dependent variables)\n",
    "\n",
    "In the same vein, the test set is also divided into two parts\n",
    "the X_test(independent variables) and its corresponding dependent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a34ace03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0 0.0 1.0 38.77777777777778 52000.0]\n",
      " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
      " [1.0 0.0 0.0 44.0 72000.0]\n",
      " [0.0 0.0 1.0 38.0 61000.0]\n",
      " [0.0 0.0 1.0 27.0 48000.0]\n",
      " [1.0 0.0 0.0 48.0 79000.0]\n",
      " [0.0 1.0 0.0 50.0 83000.0]\n",
      " [1.0 0.0 0.0 35.0 58000.0]]\n"
     ]
    }
   ],
   "source": [
    "# independent variables\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "01d7dc6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "#dependent variables\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2c88d9df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0 1.0 0.0 30.0 54000.0]\n",
      " [1.0 0.0 0.0 37.0 67000.0]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "36f45608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27599d3",
   "metadata": {},
   "source": [
    "# Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbb945d",
   "metadata": {},
   "source": [
    "## This makes all features scale across board. That is to make sure some features are not dominated than others when using a machine learning model\n",
    "Feature scaling is not used all the time with regard to machine learning models\n",
    "\n",
    "## The most common feature scaling techniques are\n",
    "1. Standardisation: this is x-mean(x) divided by standard deviation of x.\n",
    "\n",
    "2. Normalisation: x-min(x) divided by max(x)-min(x)\n",
    "\n",
    "## Most recommended is standardisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "385e158e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    44.0\n",
       "1    27.0\n",
       "2    30.0\n",
       "3    38.0\n",
       "4    40.0\n",
       "5    35.0\n",
       "6     NaN\n",
       "7    48.0\n",
       "8    50.0\n",
       "9    37.0\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c4f01b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0 0.0 1.0 -0.1915918438457856 -1.0781259408412427]\n",
      " [0.0 1.0 0.0 -0.014117293757057902 -0.07013167641635401]\n",
      " [1.0 0.0 0.0 0.5667085065333239 0.6335624327104546]\n",
      " [0.0 0.0 1.0 -0.3045301939022488 -0.30786617274297895]\n",
      " [0.0 0.0 1.0 -1.901801144700799 -1.4204636155515822]\n",
      " [1.0 0.0 0.0 1.1475343068237056 1.2326533634535488]\n",
      " [0.0 1.0 0.0 1.4379472069688966 1.5749910381638883]\n",
      " [1.0 0.0 0.0 -0.7401495441200352 -0.5646194287757336]]\n"
     ]
    }
   ],
   "source": [
    "# Lets apply standardisation\n",
    "# This is cannot be applied on dummy values\n",
    "# this changes brings about a range from -3 to 3\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train[:, 3:] = sc.fit_transform(X_train[:, 3:])\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1955d4f1",
   "metadata": {},
   "source": [
    "## Note: fit = apply\n",
    "## Transform = take the action or transform\n",
    "## Both can be used at the same time\n",
    "## that is fit_transform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b24a8400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0, 1.0, 0.0, -13.11078717201166, -9.309124480659081],\n",
       "       [1.0, 0.0, 0.0, -13.064139941690962, -9.309124480651798]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only use the transform method to change the X-test in order\n",
    "# to make it ready for testing the reason the fit method is \n",
    "# taken out\n",
    "X_test[:, 3:] = sc.transform(X_test[:, 3:])\n",
    "X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5206b599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>France</td>\n",
       "      <td>44.0</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spain</td>\n",
       "      <td>27.0</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Germany</td>\n",
       "      <td>30.0</td>\n",
       "      <td>54000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spain</td>\n",
       "      <td>38.0</td>\n",
       "      <td>61000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Germany</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>France</td>\n",
       "      <td>35.0</td>\n",
       "      <td>58000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Spain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>France</td>\n",
       "      <td>48.0</td>\n",
       "      <td>79000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Germany</td>\n",
       "      <td>50.0</td>\n",
       "      <td>83000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>France</td>\n",
       "      <td>37.0</td>\n",
       "      <td>67000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country   Age   Salary Purchased\n",
       "0   France  44.0  72000.0        No\n",
       "1    Spain  27.0  48000.0       Yes\n",
       "2  Germany  30.0  54000.0        No\n",
       "3    Spain  38.0  61000.0        No\n",
       "4  Germany  40.0      NaN       Yes\n",
       "5   France  35.0  58000.0       Yes\n",
       "6    Spain   NaN  52000.0        No\n",
       "7   France  48.0  79000.0       Yes\n",
       "8  Germany  50.0  83000.0        No\n",
       "9   France  37.0  67000.0       Yes"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7db6fb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
